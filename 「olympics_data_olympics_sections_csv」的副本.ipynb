{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPurHu1pG/aUVEfnR/ufqwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericatlin/ai/blob/main/%E3%80%8Colympics_data_olympics_sections_csv%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz pymupdf\n",
        "!pip install tools\n",
        "!pip install frontend\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "Eesj6mx54aRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fitz\n",
        "!pip install PyMuPDF==1.18.13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czXZT3IVBSEn",
        "outputId": "3df41c6c-e95a-4d34-f1e7-a531de7d486c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fitz in /usr/local/lib/python3.9/dist-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from fitz) (1.4.4)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.9/dist-packages (from fitz) (1.5)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.9/dist-packages (from fitz) (5.3.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.9/dist-packages (from fitz) (3.0.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.9/dist-packages (from fitz) (1.8.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from fitz) (1.10.1)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.9/dist-packages (from fitz) (0.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fitz) (1.22.4)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.9/dist-packages (from fitz) (5.0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from configobj->fitz) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.9/dist-packages (from httplib2->fitz) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (3.10.7)\n",
            "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (3.19.1)\n",
            "Requirement already satisfied: looseversion in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (1.1.2)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (2.0.0)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (8.1.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (3.0)\n",
            "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (23.0)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (1.4.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->fitz) (2022.7.1)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.9/dist-packages (from pyxnat->fitz) (0.18.3)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.9/dist-packages (from pyxnat->fitz) (4.9.2)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.9/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from pyxnat->fitz) (2.27.1)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.9/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->pyxnat->fitz) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->pyxnat->fitz) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->pyxnat->fitz) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyMuPDF==1.18.13 in /usr/local/lib/python3.9/dist-packages (1.18.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "# 開啟 PDF 檔案\n",
        "with fitz.open('./D1.pdf') as doc:\n",
        "    # 取得文件內所有頁面\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.getText(\"text\")\n",
        "text = text.replace('•','')\n",
        "    # 輸出文字\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "mkizAEKl5-q0",
        "outputId": "3646a3bd-4137-4ad0-b27d-923316db6844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mupdf: cannot open ./D1.pdf: No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-192776b01b8c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 開啟 PDF 檔案\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./D1.pdf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 取得文件內所有頁面\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/fitz/fitz.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         _fitz.Document_swiginit(\n\u001b[1;32m   3653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3654\u001b[0;31m             _fitz.new_Document(\n\u001b[0m\u001b[1;32m   3655\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiletype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m             ),\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cannot open ./D1.pdf: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import pandas as pd\n",
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "# 開啟 PDF 檔案\n",
        "with fitz.Document('./D1.pdf') as doc:\n",
        "    # 取得文件內所有頁面的文字\n",
        "    text_list = [page.get_text().replace('•','') for page in doc]\n",
        "for i in text_list:\n",
        "    print(i)\n",
        "\n",
        "# 將文字轉換為 Pandas DataFrame 物件\n",
        "text_df = pd.DataFrame({'context': text_list})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHgy7e_CB0FW",
        "outputId": "cfe8d67c-b4d2-4775-9d6b-c7a892a3034c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新冠肺炎\n",
            "\n",
            " 嚴重特殊傳染性肺炎（英語：Coronavirus disease 2019，縮寫：COVID-19[17][18]），\n",
            "是一種由嚴重急性呼吸道症候群冠狀病毒2型（縮寫：SARS-CoV-2）引發的傳染病，\n",
            "導致了一場持續的疫情，成為人類歷史上致死人數最多的流行病之一。該病已知\n",
            "的首名病人2019年末於中華人民共和國湖北省武漢市[19][註 1]確診，其後此病在全球\n",
            "範圍內陸續被檢測出。截至2023年3月10日，全球已累計報告逾6.76億名確診病例，\n",
            "逾688.1萬名患者死亡[5]，目前仍在持續擴散中。世界各國對該病致死率（CFR）的\n",
            "估計值差異甚大，截止2021年2月8日，多數國家該病的觀測致死率在0.5%-5.0%之\n",
            "間[22][註 2]，全球初步修正致死率約為2.9%[24]。\n",
            " 該疾病常見的症狀包括發燒、咳嗽、疲勞、呼吸急促、味嗅覺喪失[2][3][25][26]、肌肉\n",
            "酸痛等。自感染到出現症狀的時間通常為1至14天。至少三分之一的感染者無症狀\n",
            "[27]。大多數出現明顯症狀患者（81%）出現輕度至中度症狀（最多為輕度肺炎），\n",
            "而14%出現嚴重症狀（呼吸困難、缺氧或影像學上超過50%的肺部受累），5%出現\n",
            "危急症狀（呼吸衰竭、休克或多重器官衰竭）[1]。老年人或存在相關基礎疾病的\n",
            "患者出現嚴重症狀的風險更高。有些人在康復後的幾個月內仍會經歷一系列的影\n",
            "響，而且已經觀察到對器官的損害[28]。已展開多年的研究，以進一步調查該疾病\n",
            "的長期影響[28]。\n",
            " 病毒主要通過口鼻分泌物傳播，包括咳嗽[註 3]、打噴嚏和說話產生的飛沫[3][30][31]。\n",
            "這些飛沫通常不會在空氣中長距離傳播[3][32]。但是，站在近處的人可能會因吸入\n",
            "這些飛沫而被感染[註 4]。人們也可能通過接觸受污染的表面，然後再接觸自己的臉\n",
            "而受到感染[3][30]。在封閉的空間內，也可能通過能夠在空氣中懸浮較長時間的氣\n",
            "膠傳播[33]。在出現症狀後的前三天最具傳染性，儘管在症狀出現前和無症狀的人\n",
            "身上都有可能傳播[3][30]，而有研究顯示約40%-45%的患者為無症狀感染者[34][35]。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_questions(context):\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-003\",\n",
        "            prompt=f\"幫我寫5個問題集由下面的文件\\n\\nText: {context}\\n\\nQuestions:\\n1.\",\n",
        "            temperature=0,\n",
        "            max_tokens=300,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0,\n",
        "            stop=[\"\\n\\n\"]\n",
        "        )\n",
        "        return response['choices'][0]['text']\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "# 生成問題\n",
        "text_df['questions'] = text_df['context'].apply(lambda x: get_questions(x))\n",
        "text_df['questions'] = \"1.\" + text_df['questions']\n",
        "print(text_df[['questions']].values[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4tJaiuDL6c5",
        "outputId": "05a314ec-043a-4ddc-fdf1-6b55653669c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 什麼是新冠肺炎？\n",
            "2. 新冠肺炎有哪些症狀？\n",
            "3. 新冠肺炎有什麼治療方法？\n",
            "4. 新冠肺炎有什麼預防措施？\n",
            "5. 新冠肺炎有什麼潛在風險？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answers(row):\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"davinci-instruct-beta-v3\",\n",
        "            prompt=f\"幫我寫5個答案集由下面的文件\\n\\nText: {row.context}\\n\\nQuestions:\\n{row.questions}\\n\\nAnswers:\\n1.\",\n",
        "            temperature=0,\n",
        "            max_tokens=500,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "        )\n",
        "        return response['choices'][0]['text']\n",
        "    except Exception as e:\n",
        "        print (e)\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "text_df['answers']= text_df.apply(get_answers, axis=1)\n",
        "text_df['answers'] = \"1.\" + text_df.answers\n",
        "text_df = text_df.dropna().reset_index().drop('index',axis=1)\n",
        "print(text_df[['answers']].values[0][0])"
      ],
      "metadata": {
        "id": "5N0oV2KJaClG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6667bdfc-0dbd-42d3-f410-0901c38a5223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This model's maximum context length is 2049 tokens, however you requested 2251 tokens (1751 in your prompt; 500 for the completion). Please reduce your prompt; or completion length.\n",
            "1. 新冠肺炎是一種由新型冠狀病毒引起的肺炎，是近年來發病率和死亡率最高的呼吸道傳染病之一。\n",
            "2. 新冠肺炎的主要症狀有咳嗽、發燒、乏力、呼吸困難等。\n",
            "3. 新冠肺炎的治療方法主要有抗病毒藥物治療和支持治療。\n",
            "4. 新冠肺炎的預防措施主要有個人防護措施和環境防護措施。\n",
            "5. 新冠肺炎的潛在風險主要有重症發病的風險和死亡率高的風險。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df.to_csv('covid_qa.csv', index=False)"
      ],
      "metadata": {
        "id": "q4HVyXt8aCeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.tokens<2000]\n",
        "df[['context', 'tokens']].rename(columns={'context':'text','tokens':'metadata'}).to_json('olympics-data/olympics_search.jsonl', orient='records', lines=True)\n",
        "\n",
        "search_file = openai.File.create(\n",
        "  file=open(\"olympics-data/olympics_search.jsonl\"),\n",
        "  purpose='search'\n",
        ")\n",
        "olympics_search_fileid = search_file['id']"
      ],
      "metadata": {
        "id": "iY4-GfJAaCTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from answers_with_ft import create_context, answer_question\n",
        "print(create_context(\"Where did women's 4 x 100 metres relay event take place during the 2020 Summer Olympics?\", olympics_search_fileid, max_len=400))"
      ],
      "metadata": {
        "id": "GPRrlEPCaO1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(olympics_search_fileid, \"davinci-instruct-beta-v3\", \n",
        "            \"Where did women's 4 x 100 metres relay event take place during the 2020 Summer Olympics?\")"
      ],
      "metadata": {
        "id": "kMwCt1HKaOrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(olympics_search_fileid, \"davinci-instruct-beta-v3\", \n",
        "            \"Where did women's 4 x 100 metres relay event take place during the 2048 Summer Olympics?\", max_len=1000)"
      ],
      "metadata": {
        "id": "m245B4PtaVb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_context(title, heading, question, max_len=1800, search_model='ada', max_rerank=10):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of the search model in retrieving the correct context\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    title: str\n",
        "        The title of the Wikipedia page\n",
        "    heading: str\n",
        "        The heading of the Wikipedia section\n",
        "    qusetion: str\n",
        "        The question\n",
        "    max_len: int\n",
        "        The maximum length of the context\n",
        "    search_model: str\n",
        "        The search model to use - `ada` is most cost effective\n",
        "    max_rerank: int\n",
        "        The maximum number of reranking documents to use the search model on\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    rank: int\n",
        "        The rank of the correct context\n",
        "    token_length: int\n",
        "        The number of tokens needed to obtain the correct context\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        results = openai.Engine(search_model).search(\n",
        "            search_model=search_model, \n",
        "            query=question, \n",
        "            max_rerank=max_rerank,\n",
        "            file=olympics_search_fileid,\n",
        "            return_metadata=True\n",
        "        )\n",
        "        index=-1\n",
        "        returns = []\n",
        "        cur_len = 0\n",
        "        for result in results['data']:\n",
        "            cur_len += int(result['metadata']) + 4 # we add 4 tokens for the separator `\\n\\n###\\n\\n`\n",
        "            if cur_len > max_len:\n",
        "                break\n",
        "            returns.append(result['text'])\n",
        "            res = result['text'].split('\\n')\n",
        "            if res[0] == title and res[1] == heading:\n",
        "                index = len(returns) - 1\n",
        "                break\n",
        "        return index, cur_len\n",
        "    except Exception as e:\n",
        "        #print (e)\n",
        "        return []\n",
        "print(check_context(\"Athletics at the 2020 Summer Olympics – Women's 4 × 100 metres relay\", \"Summary\", \"Where did women's 4 x 100 metres relay event take place during "
      ],
      "metadata": {
        "id": "LWeKHsj8aVYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada_results = df.apply(lambda x: [\n",
        "                    check_context( x.title, \n",
        "                                   x.heading, \n",
        "                                   q[3:],     # remove the number prefix\n",
        "                                   max_len=1000000, # set a large number to get the full context \n",
        "                                   search_model='ada', \n",
        "                                   max_rerank=200,\n",
        "                                 ) \n",
        "                    for q in (x.questions).split('\\n') # split the questions\n",
        "                    if len(q) >10 # remove the empty questions\n",
        "                ], axis=1)\n",
        "ada_results.head()"
      ],
      "metadata": {
        "id": "642_p5lMaVXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = pd.concat([ada_results], axis=1)\n",
        "out.columns = ['ada']\n",
        "out.to_csv('olympics-data/search_engine_results.csv')"
      ],
      "metadata": {
        "id": "wVTckLdKaVUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_lists(out):\n",
        "    \"\"\"\n",
        "    Expand a pandas series containing lists into a series, where each list element becomes a value on its own\n",
        "\n",
        "    Input is a row per paragraph, which has multiple questions\n",
        "    Output is a row per question\n",
        "    \"\"\"\n",
        "    cols = [pd.DataFrame(out[name].tolist()).stack().reset_index(level=1, drop=True).rename(name) for name in out.columns] \n",
        "    return pd.concat(cols, axis=1)\n",
        "\n",
        "out_expanded = expand_lists(out)\n",
        "out_expanded['rank'] = out_expanded.ada.apply(lambda x: x[0] if x != [] else -2)\n",
        "out_expanded['tokens'] = out_expanded.ada.apply(lambda x: x[1] if x != [] else -2)"
      ],
      "metadata": {
        "id": "n3HzrVWWaVSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "within_2k = (out_expanded.tokens < 2000).mean()\n",
        "print(f\"{within_2k*100:.1f}% of relevant paragraphs are retrieved within the first 2k tokens\")"
      ],
      "metadata": {
        "id": "jZF8KSNLaVO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "outside_200 = (out_expanded['rank'] == -1).mean()\n",
        "print(f\"{outside_200*100:.1f}% of relevant paragraphs are not retrieved within the first 200 results\")"
      ],
      "metadata": {
        "id": "ho3C00g1aVMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot a histogram, and add axis descriptions and title\n",
        "out_expanded[(out_expanded['rank'] >=0)&(out_expanded['rank'] <30)]['rank'].hist(bins=29)\n",
        "plt.xlabel('rank')\n",
        "plt.ylabel('count')\n",
        "plt.title('Histogram of ranks of retrieved paragraphs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H6GNKx-3aVKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_expanded[(out_expanded.tokens>=0)&(out_expanded.tokens < 2000)]['tokens'].hist(bins=29)\n",
        "plt.xlabel('tokens')\n",
        "plt.ylabel('count')\n",
        "plt.title('Histogram of the number of minimum tokens needed')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E8MN5XU7aVHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalized value_counts\n",
        "out_expanded['rank'].value_counts(normalize=True).sort_index()[:13]"
      ],
      "metadata": {
        "id": "d3MAleykaVFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "df = pd.read_csv('olympics-data/olympics_qa.csv')\n",
        "olympics_search_fileid = \"file-c3shd8wqF3vSCKaukW4Jr1TT\"\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zx2ku6qkaU08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "id": "64_ir1xLbInr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.context.str.contains('->').sum()"
      ],
      "metadata": {
        "id": "rh3YrQWTbIbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_random_similar_contexts(question, context, file_id=olympics_search_fileid, search_model='ada', max_rerank=10):\n",
        "    \"\"\"\n",
        "    Find similar contexts to the given context using the search file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = openai.Engine(search_model).search(\n",
        "            search_model=search_model, \n",
        "            query=question, \n",
        "            max_rerank=max_rerank,\n",
        "            file=file_id\n",
        "        )\n",
        "        candidates = []\n",
        "        for result in results['data'][:3]:\n",
        "            if result['text'] == context:\n",
        "                continue\n",
        "            candidates.append(result['text'])\n",
        "        random_candidate = random.choice(candidates)\n",
        "        return random_candidate\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return \"\"\n",
        "\n",
        "def create_fine_tuning_dataset(df, discriminator=False, n_negative=1, add_related=False):\n",
        "    \"\"\"\n",
        "    Create a dataset for fine tuning the OpenAI model; either for a discriminator model, \n",
        "    or a model specializing in Q&A, where it says if no relevant context is found.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df: pd.DataFrame\n",
        "        The dataframe containing the question, answer and context pairs\n",
        "    discriminator: bool\n",
        "        Whether to create a dataset for the discriminator\n",
        "    n_negative: int\n",
        "        The number of random negative samples to add (using a random context)\n",
        "    add_related: bool\n",
        "        Whether to add the related contexts to the correct context. These are hard negative examples\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        The dataframe containing the prompts and completions, ready for fine-tuning\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for i, row in df.iterrows():\n",
        "        for q, a in zip((\"1.\" + row.questions).split('\\n'), (\"1.\" + row.answers).split('\\n')):\n",
        "            if len(q) >10 and len(a) >10:\n",
        "                if discriminator:\n",
        "                    rows.append({\"prompt\":f\"{row.context}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" yes\"})\n",
        "                else:\n",
        "                    rows.append({\"prompt\":f\"{row.context}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" {a[2:].strip()}\"})\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        for q in (\"1.\" + row.questions).split('\\n'):\n",
        "            if len(q) >10:\n",
        "                for j in range(n_negative + (2 if add_related else 0)):\n",
        "                    random_context = \"\"\n",
        "                    if j == 0 and add_related:\n",
        "                        # add the related contexts based on originating from the same wikipedia page\n",
        "                        subset = df[(df.title == row.title) & (df.context != row.context)]\n",
        "                        \n",
        "                        if len(subset) < 1:\n",
        "                            continue\n",
        "                        random_context = subset.sample(1).iloc[0].context\n",
        "                    if j == 1 and add_related:\n",
        "                        # add the related contexts based on the most similar contexts according to the search\n",
        "                        random_context = get_random_similar_contexts(q[2:].strip(), row.context, search_model='ada', max_rerank=10)\n",
        "                    else:\n",
        "                        while True:\n",
        "                            # add random context, which isn't the correct context\n",
        "                            random_context = df.sample(1).iloc[0].context\n",
        "                            if random_context != row.context:\n",
        "                                break\n",
        "                    if discriminator:\n",
        "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" no\"})\n",
        "                    else:\n",
        "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" No appropriate context found to answer the question.\"})\n",
        "\n",
        "    return pd.DataFrame(rows) "
      ],
      "metadata": {
        "id": "cr3I-mJIbIFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, is_disc in [('discriminator', True), ('qa', False)]:\n",
        "    for train_test, dt in [('train', train_df), ('test', test_df)]:\n",
        "        ft = create_fine_tuning_dataset(dt, discriminator=is_disc, n_negative=1, add_related=True)\n",
        "        ft.to_json(f'{name}_{train_test}.jsonl', orient='records', lines=True)"
      ],
      "metadata": {
        "id": "J4v5kb26bU_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"olympics-data/discriminator_train.jsonl\" -v \"olympics-data/discriminator_test.jsonl\" --batch_size 16  --compute_classification_metrics --classification_positive_class \" yes\" --m"
      ],
      "metadata": {
        "id": "6jPlNbncbVaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"olympics-data/qa_train.jsonl\" -v \"olympics-data/qa_test.jsonl\" --batch_size 16"
      ],
      "metadata": {
        "id": "ASJ0QSNhbV7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_discriminator = \"curie:ft-openai-internal-2021-08-23-23-58-57\"\n",
        "ft_qa = \"curie:ft-openai-internal-2021-08-23-17-54-10\"\n",
        "\n",
        "def apply_ft_discriminator(context, question, discriminator_model):\n",
        "    \"\"\"\n",
        "    Apply the fine tuned discriminator to a question, to assess whether it can be answered from the context.\n",
        "    \"\"\"\n",
        "    prompt = f\"{context}\\nQuestion: {question}\\n Related:\"\n",
        "    result = openai.Completion.create(model=discriminator_model, prompt=prompt, max_tokens=1, temperature=0, top_p=1, n=1, logprobs=2)\n",
        "    return result['choices'][0]['logprobs']['top_logprobs']\n",
        "\n",
        "apply_ft_discriminator('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.', \n",
        "                        'What was the first human-made object in space?', ft_discriminator)"
      ],
      "metadata": {
        "id": "DJWXQ2eDbdi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_ft_qa_answer(context, question, answering_model):\n",
        "    \"\"\"\n",
        "    Apply the fine tuned discriminator to a question\n",
        "    \"\"\"\n",
        "    prompt = f\"{context}\\nQuestion: {question}\\nAnswer:\"\n",
        "    result = openai.Completion.create(model=answering_model, prompt=prompt, max_tokens=30, temperature=0, top_p=1, n=1, stop=['.','\\n'])\n",
        "    return result['choices'][0]['text']\n",
        "\n",
        "apply_ft_qa_answer('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.', \n",
        "                    'What was the first human-made object in space?', ft_qa)"
      ],
      "metadata": {
        "id": "Wp68Ccvtbdsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply_ft_qa_answer('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.',\n",
        "                    'What is impressive about the Soviet Union?', ft_qa)"
      ],
      "metadata": {
        "id": "7zt28Ln-bd5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply_ft_qa_answer('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.',\n",
        "                    'How many cars were produced in the Soviet Union in 1970?', ft_qa)"
      ],
      "metadata": {
        "id": "4XuhgDlubeGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question_conditionally(answering_model, discriminator_model, context, question, discriminator_logprob_yes_modifier=0):\n",
        "    logprobs = apply_ft_discriminator(context, question, discriminator_model)\n",
        "    yes_logprob = logprobs[' yes'] if ' yes' in logprobs else -100\n",
        "    no_logprob = logprobs[' no'] if ' no' in logprobs else -100\n",
        "    if yes_logprob + discriminator_logprob_yes_modifier < no_logprob:\n",
        "        return \" No appropriate context found to answer the question based on the discriminator.\"\n",
        "    return apply_ft_qa_answer(context, question, answering_model)\n",
        "answer_question_conditionally(ft_qa, ft_discriminator, \n",
        "                                \"Crowdless games are a rare although not unheard-of occurrence in sports. \\\n",
        "                                 When they do occur, it is usually the result of events beyond the control \\\n",
        "                                 of the teams or fans, such as weather-related concerns, public health concerns, \\\n",
        "                                 or wider civil disturbances unrelated to the game. For instance, \\\n",
        "                                 the COVID-19 pandemic caused many sports leagues around the world \\\n",
        "                                 to be played behind closed doors.\",\n",
        "                                \"Could weather cause a sport event to have no crowd?\")"
      ],
      "metadata": {
        "id": "i4e7AQAgbegj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from answers_with_ft import answer_question\n",
        "answer_question(olympics_search_fileid, ft_qa, \"Which country won the Women's football tournament at the 2020 Olympic games?\")"
      ],
      "metadata": {
        "id": "5DWMgW43bqri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}